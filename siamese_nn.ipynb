{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision opencv-python pillow numpy matplotlib deep-sort-realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_NAME = 'DSC_2411.MOV'\n",
    "video_path = fr\"tracking_rukomet\\{VIDEO_NAME}\"\n",
    "output_txt_path = fr\"tracking_rukomet\\predictions\\{VIDEO_NAME.replace('.MOV', '_siamese.txt')}\"\n",
    "\n",
    "# Load Siamese model (ResNet18 for feature extraction)\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.feature_extractor = models.resnet18(pretrained=True)\n",
    "        self.feature_extractor.fc = nn.Identity()  # Remove classification layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.feature_extractor(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "snn = SiameseNetwork().to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load model and set to eval mode\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "snn = SiameseNetwork().to(device).eval()\n",
    "\n",
    "# Define preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Function to get feature embedding\n",
    "def get_embedding(image):\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        embedding = snn(image).cpu().numpy()\n",
    "    return embedding\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Select object to track\n",
    "ret, frame = cap.read()\n",
    "bbox = cv2.selectROI(\"Select Object\", frame, fromCenter=False, showCrosshair=True)\n",
    "cv2.destroyWindow(\"Select Object\")\n",
    "\n",
    "# Get reference embedding of selected object\n",
    "x, y, w, h = map(int, bbox)\n",
    "reference_patch = frame[y:y+h, x:x+w]\n",
    "reference_embedding = get_embedding(reference_patch)\n",
    "\n",
    "# Main tracking loop\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Define search region (expand around previous bbox)\n",
    "    search_x, search_y, search_w, search_h = max(0, x - 20), max(0, y - 20), w + 40, h + 40\n",
    "    search_patch = frame[search_y:search_y+search_h, search_x:search_x+search_w]\n",
    "\n",
    "    # Divide search area into smaller patches and compare embeddings\n",
    "    best_match, best_score = None, float(\"inf\")\n",
    "    step = 10\n",
    "    for i in range(0, search_w - w, step):\n",
    "        for j in range(0, search_h - h, step):\n",
    "            candidate_patch = search_patch[j:j+h, i:i+w]\n",
    "            if candidate_patch.shape[0] != h or candidate_patch.shape[1] != w:\n",
    "                continue\n",
    "            \n",
    "            candidate_embedding = get_embedding(candidate_patch)\n",
    "            score = np.linalg.norm(reference_embedding - candidate_embedding)\n",
    "            \n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_match = (search_x + i, search_y + j, w, h)\n",
    "\n",
    "    # Update tracking box\n",
    "    if best_match:\n",
    "        x, y, w, h = best_match\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display frame\n",
    "    cv2.imshow(\"Siamese Tracker\", frame)\n",
    "\n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
