{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\jelen\\miniconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\jelen\\miniconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\jelen\\miniconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: pillow in c:\\users\\jelen\\miniconda3\\lib\\site-packages (11.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jelen\\miniconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jelen\\miniconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: deep-sort-realtime in c:\\users\\jelen\\miniconda3\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\jelen\\miniconda3\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\jelen\\miniconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\jelen\\miniconda3\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jelen\\miniconda3\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jelen\\miniconda3\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jelen\\miniconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\jelen\\miniconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jelen\\miniconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jelen\\miniconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jelen\\miniconda3\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jelen\\miniconda3\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jelen\\miniconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jelen\\miniconda3\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jelen\\miniconda3\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jelen\\miniconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy in c:\\users\\jelen\\miniconda3\\lib\\site-packages (from deep-sort-realtime) (1.13.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jelen\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jelen\\miniconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision opencv-python pillow numpy matplotlib deep-sort-realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_NAME = 'DSC_2414.MOV'\n",
    "video_path = fr\"tracking_rukomet\\{VIDEO_NAME}\"\n",
    "output_txt_path = fr\"tracking_rukomet\\predictions\\{VIDEO_NAME.replace('.MOV', '_siameseNN.txt')}\"\n",
    "detector = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "detector.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siamese_network():\n",
    "    class SiameseNetwork(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(SiameseNetwork, self).__init__()\n",
    "            self.feature_extractor = models.resnet18(pretrained=True)\n",
    "            self.feature_extractor.fc = nn.Identity()\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.feature_extractor(x)\n",
    "\n",
    "    return SiameseNetwork().to(device).eval()\n",
    "\n",
    "snn = get_siamese_network()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "os.makedirs(os.path.dirname(output_txt_path), exist_ok=True)\n",
    "\n",
    "trackers = {} \n",
    "next_person_id = 0\n",
    "\n",
    "def detect_people(frame):\n",
    "    img_tensor = transforms.functional.to_tensor(frame).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        preds = detector(img_tensor)[0]\n",
    "    \n",
    "    boxes = preds[\"boxes\"].cpu().numpy()\n",
    "    scores = preds[\"scores\"].cpu().numpy()\n",
    "    labels = preds[\"labels\"].cpu().numpy()\n",
    "\n",
    "    detections = []\n",
    "    for box, score, label in zip(boxes, scores, labels):\n",
    "        if score > 0.6 and label == 1:\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            detections.append((x1, y1, x2, y2, score))\n",
    "    \n",
    "    return detections\n",
    "\n",
    "def extract_embedding(frame, box):\n",
    "    x1, y1, x2, y2 = box\n",
    "    crop = frame[y1:y2, x1:x2]\n",
    "    img_tensor = transform(crop).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        embedding = snn(img_tensor).cpu().numpy()\n",
    "    return embedding.flatten()\n",
    "\n",
    "def match_detections(previous_trackers, current_detections, frame):\n",
    "    global next_person_id\n",
    "    \n",
    "    if len(previous_trackers) == 0:\n",
    "        for det in current_detections:\n",
    "            person_id = next_person_id\n",
    "            next_person_id += 1\n",
    "            trackers[person_id] = extract_embedding(frame, det[:4])\n",
    "            yield person_id, det\n",
    "        return\n",
    "    \n",
    "    prev_ids = list(previous_trackers.keys())\n",
    "    prev_embeddings = np.array(list(previous_trackers.values()))\n",
    "    \n",
    "    current_embeddings = [extract_embedding(frame, det[:4]) for det in current_detections]\n",
    "    \n",
    "    if len(current_embeddings) == 0:\n",
    "        return\n",
    "    \n",
    "    cost_matrix = np.zeros((len(prev_embeddings), len(current_embeddings)))\n",
    "    for i, prev_emb in enumerate(prev_embeddings):\n",
    "        for j, curr_emb in enumerate(current_embeddings):\n",
    "            cost_matrix[i, j] = 1 - np.dot(prev_emb, curr_emb) / (np.linalg.norm(prev_emb) * np.linalg.norm(curr_emb))\n",
    "    \n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    \n",
    "    matched = set()\n",
    "    for i, j in zip(row_ind, col_ind):\n",
    "        if cost_matrix[i, j] < 0.5:  # Threshold for similarity\n",
    "            person_id = prev_ids[i]\n",
    "            trackers[person_id] = current_embeddings[j]\n",
    "            matched.add(j)\n",
    "            yield person_id, current_detections[j]\n",
    "    \n",
    "    for j, det in enumerate(current_detections):\n",
    "        if j not in matched:\n",
    "            person_id = next_person_id\n",
    "            next_person_id += 1\n",
    "            trackers[person_id] = extract_embedding(frame, det[:4])\n",
    "            yield person_id, det\n",
    "\n",
    "with open(output_txt_path, \"w\") as f:\n",
    "    frame_id = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_id += 1\n",
    "        detections = detect_people(frame)\n",
    "        \n",
    "        new_trackers = {}\n",
    "        for person_id, (x1, y1, x2, y2, score) in match_detections(trackers, detections, frame):\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            new_trackers[person_id] = trackers[person_id]\n",
    "            \n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, str(person_id), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "            f.write(f\"{frame_id},{person_id},{x1},{y1},{w},{h},1,-1,-1,-1\\n\")\n",
    "        \n",
    "        trackers = new_trackers\n",
    "        cv2.imshow(\"Siamese Tracker\", frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"Tracking results saved to: {output_txt_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
