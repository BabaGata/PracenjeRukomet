{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse the tracking files\n",
    "def parse_tracking_file(file_path):\n",
    "    \"\"\"\n",
    "    Parses the tracking result file and returns a dictionary with frame_id as key\n",
    "    and a list of detections in the format (track_id, x, y, w, h)\n",
    "    \"\"\"\n",
    "    tracking_data = {}\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\",\")\n",
    "            frame_id = int(parts[0])\n",
    "            track_id = int(parts[1])\n",
    "            x, y, w, h = map(int, parts[2:6])\n",
    "            if frame_id not in tracking_data:\n",
    "                tracking_data[frame_id] = []\n",
    "            tracking_data[frame_id].append((track_id, x, y, w, h))\n",
    "    return tracking_data\n",
    "\n",
    "# Function to parse the ground truth file\n",
    "def parse_gt_file(gt_file_path):\n",
    "    \"\"\"\n",
    "    Parses the ground truth file and returns a dictionary with frame_id as key\n",
    "    and a list of GT boxes in the format (track_id, x, y, w, h)\n",
    "    \"\"\"\n",
    "    gt_data = {}\n",
    "    with open(gt_file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\",\")\n",
    "            frame_id = int(parts[0])\n",
    "            track_id = int(parts[1])\n",
    "            x, y, w, h = map(int, parts[2:6])\n",
    "            if frame_id not in gt_data:\n",
    "                gt_data[frame_id] = []\n",
    "            gt_data[frame_id].append((track_id, x, y, w, h))\n",
    "    return gt_data\n",
    "\n",
    "# IoU calculation function\n",
    "def iou(bb1, bb2):\n",
    "    \"\"\"\n",
    "    Compute IoU (Intersection over Union) between two bounding boxes.\n",
    "    Each box is in the format (x, y, w, h)\n",
    "    \"\"\"\n",
    "    x1, y1, w1, h1 = bb1\n",
    "    x2, y2, w2, h2 = bb2\n",
    "\n",
    "    xi1 = max(x1, x2)\n",
    "    yi1 = max(y1, y2)\n",
    "    xi2 = min(x1 + w1, x2 + w2)\n",
    "    yi2 = min(y1 + h1, y2 + h2)\n",
    "\n",
    "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "    area1 = w1 * h1\n",
    "    area2 = w2 * h2\n",
    "    union_area = area1 + area2 - inter_area\n",
    "\n",
    "    return inter_area / union_area if union_area != 0 else 0\n",
    "\n",
    "# Evaluation function for tracking\n",
    "def evaluate_tracking(gt_data, pred_data, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate tracking performance based on IoU threshold.\n",
    "    Returns MOTA, IDF1 scores.\n",
    "    \"\"\"\n",
    "    tp = 0  # True positives\n",
    "    fp = 0  # False positives\n",
    "    fn = 0  # False negatives\n",
    "    num_tracks = 0  # Total number of tracks\n",
    "\n",
    "    for frame_id in gt_data:\n",
    "        if frame_id not in pred_data:\n",
    "            continue\n",
    "\n",
    "        gt_tracks = gt_data[frame_id]\n",
    "        pred_tracks = pred_data[frame_id]\n",
    "\n",
    "        # Match predicted tracks with ground truth\n",
    "        matched_gt = set()\n",
    "        matched_pred = set()\n",
    "\n",
    "        for pred in pred_tracks:\n",
    "            best_iou = 0\n",
    "            best_gt = None\n",
    "            for gt in gt_tracks:\n",
    "                if gt[0] in matched_gt:  # Skip already matched GTs\n",
    "                    continue\n",
    "                iou_score = iou(pred[1:], gt[1:])\n",
    "                if iou_score > best_iou:\n",
    "                    best_iou = iou_score\n",
    "                    best_gt = gt\n",
    "\n",
    "            if best_iou >= iou_threshold:\n",
    "                tp += 1\n",
    "                matched_gt.add(best_gt[0])\n",
    "                matched_pred.add(pred[0])\n",
    "            else:\n",
    "                fp += 1\n",
    "\n",
    "        fn += len(gt_tracks) - len(matched_gt)\n",
    "        num_tracks += len(gt_tracks)\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    mota = 1 - (fp + fn) / num_tracks if num_tracks > 0 else 0\n",
    "    idf1 = 2 * tp / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0\n",
    "\n",
    "    return mota, idf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/30 21:53:06 INFO mlflow.tracking.fluent: Experiment with name 'Tracking_Evaluation_Experiment' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "# Set MLflow experiment name (you can customize this)\n",
    "mlflow.set_experiment('Tracking_Evaluation_Experiment')\n",
    "\n",
    "gt_file_path = \"tracking_rukomet/tracks_gt/DSC_2411_trk-ispravljen.txt\"\n",
    "pred_deepsort_file = \"tracking_rukomet/predictions/DSC_2411_deepsort.txt\"\n",
    "pred_norfair_file = \"tracking_rukomet/predictions/DSC_2411_norfair.txt\"\n",
    "\n",
    "# Parse ground truth and predictions\n",
    "gt_data = parse_gt_file(gt_file_path)\n",
    "pred_deepsort_data = parse_tracking_file(pred_deepsort_file)\n",
    "pred_norfair_data = parse_tracking_file(pred_norfair_file)\n",
    "\n",
    "# MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log parameters (you can log the IoU threshold as well)\n",
    "    mlflow.log_param(\"iou_threshold\", 0.5)\n",
    "\n",
    "    # Evaluate DeepSORT predictions\n",
    "    mota_deepsort, idf1_deepsort = evaluate_tracking(gt_data, pred_deepsort_data)\n",
    "    mlflow.log_metric(\"MOTA_DeepSORT\", mota_deepsort)\n",
    "    mlflow.log_metric(\"IDF1_DeepSORT\", idf1_deepsort)\n",
    "\n",
    "    # Evaluate Norfair predictions\n",
    "    mota_norfair, idf1_norfair = evaluate_tracking(gt_data, pred_norfair_data)\n",
    "    mlflow.log_metric(\"MOTA_Norfair\", mota_norfair)\n",
    "    mlflow.log_metric(\"IDF1_Norfair\", idf1_norfair)\n",
    "\n",
    "    # End the MLflow run\n",
    "    mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
